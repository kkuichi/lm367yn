{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54f7df2-feaa-40e2-9323-c5e9a42f2caa",
   "metadata": {},
   "source": [
    "# ConvNeXt Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa8b5d8-2f42-4eef-8a46-d39480cfbf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.50.0)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.12/site-packages (1.0.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3f9b0-f1e3-422c-824a-8fd646fc73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Meteors: 5191, Non-Meteors: 2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [1:49:45<00:00,  6.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.0889, Val Loss=0.0588\n",
      "âœ… Model saved (best so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [2:36:02<00:00,  9.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.0265, Val Loss=0.0126\n",
      "âœ… Model saved (best so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30:  13%|â–ˆâ–Ž        | 132/991 [20:01<2:47:40, 11.71s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# Dataset class\n",
    "class MeteorDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = [fname for fname in os.listdir(image_dir) if fname.endswith(('.jpg', '.png'))]\n",
    "        self.image_paths = [os.path.join(image_dir, fname) for fname in self.image_names]\n",
    "        self.label_paths = [os.path.join(label_dir, fname.replace('.jpg', '.txt').replace('.png', '.txt')) for fname in self.image_names]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label_path = self.label_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "                label = 1 if '0' in content else 0\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(720, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((720, 720)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "data_path = \"/home/jovyan/data/lightning/LiviaMurankova/new/namnozene_meteory/DP_rozdelenie_dat/data_split_v2\"\n",
    "train_dataset = MeteorDataset(f\"{data_path}/train/images\", f\"{data_path}/train/labels\", transform=train_transforms)\n",
    "valid_dataset = MeteorDataset(f\"{data_path}/valid/images\", f\"{data_path}/valid/labels\", transform=valid_transforms)\n",
    "\n",
    "# Weighted sampler\n",
    "label_list = [int(train_dataset.__getitem__(idx)[1].item()) for idx in range(len(train_dataset))]\n",
    "num_non_meteor, num_meteor = label_list.count(0), label_list.count(1)\n",
    "print(f\"ðŸ“Š Meteors: {num_meteor}, Non-Meteors: {num_non_meteor}\")\n",
    "weights = [1.0 / num_non_meteor if label == 0 else 1.0 / num_meteor for label in label_list]\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(label_list), replacement=True)\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.75, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = targets.unsqueeze(1)\n",
    "        BCE_loss = self.bce(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model(\"convnext_small\", pretrained=True, num_classes=1).to(device)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.num_features, 1)\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "criterion = FocalLoss(alpha=0.75, gamma=2)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=2e-4)\n",
    "\n",
    "epochs = 30\n",
    "num_training_steps = len(train_loader) * epochs\n",
    "num_warmup_steps = len(train_loader) * 5  # 5 warmup epoch steps\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience, trigger_times = 5, 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"datasetv2_best_convnext_model_v65.pth\")\n",
    "        print(\"âœ… Model saved (best so far)\")\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"âš ï¸ Early stopping counter: {trigger_times}/{patience}\")\n",
    "        if trigger_times >= patience:\n",
    "            print(\"â›” Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "print(\"ðŸŽ‰ Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c093ab-3aa6-46d6-8951-c2d6ceac7d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
